{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis of Food Recipes and Reviews\n",
    "\n",
    "**Name(s)**: Kristen Lee, Jordi Pham\n",
    "\n",
    "**Website Link**: <a href='https://kristen-lee-120.github.io/wokingwithdata/'> Woking with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "# from dsc80_utils import * # Feel free to uncomment and use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, Binarizer, FunctionTransformer, QuantileTransformer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recipes and ratings dataset is a dataset that revolves around recipes for food and reviews for how well those recipes did. For our project, we are particularly interested in what is the relationship between cooking time and the average rating of recipes. Readers of should care about our dataset and questions because they can provide a baseline when choosing a recipe to cook for their next meal. Per our given csv files, `interactions` is a dataset with 731927 rows, `recipes` is a dataset with 83782 rows, and the left-merged dataset evaluates to 234429 rows of data. The columns that will prove most relevant to our question are `rating` (user-given rating of the recipe) and `minutes` (preparation time of the recipe). Using these two columns, we believe we will be able to compile the right information to hopefully answer our data science question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = pd.read_csv('../RAW_recipes_copy.csv')\n",
    "interactions = pd.read_csv('../RAW_interactions_copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recipes.shape)\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interactions.shape)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Merge Interactions to Recipes - Keep All Recipes\n",
    "main = recipes.merge(interactions, how='left', left_on='id', right_on='recipe_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main.shape)\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Rating Column - 0 to NaN\n",
    "main['rating'] = main['rating'].replace(0, np.nan)\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Average Rating Column\n",
    "# Creating Series of avg ratings\n",
    "avg_ratings = main.groupby('id')['rating'].mean()\n",
    "\n",
    "# map it onto the original df for the new column\n",
    "main['avg_rating'] = main['id'].map(avg_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view to check\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning Nutrition Column\n",
    "# Define column names\n",
    "nutrition_cols = ['calories', \n",
    "                  'total_fat_pdv', \n",
    "                  'sugar_pdv', \n",
    "                  'sodium_pdv', \n",
    "                  'protein_pdv', \n",
    "                  'saturated_fat_pdv', \n",
    "                  'carbohydrates_pdv']\n",
    "\n",
    "# Function to process nutrition data\n",
    "def process_nutrients(nutri_str):\n",
    "    try:\n",
    "        nutri_list = [float(x) for x in nutri_str.strip('[]').split(', ')]  # Convert to float for numerical operations\n",
    "        if len(nutri_list) == len(nutrition_cols):\n",
    "            return nutri_list\n",
    "        else:\n",
    "            return [None] * len(nutrition_cols)  # Handle unexpected lengths\n",
    "    except:\n",
    "        return [None] * len(nutrition_cols)  # Handle errors gracefully\n",
    "\n",
    "# Apply function and expand into multiple columns\n",
    "main[nutrition_cols] = main['nutrition'].apply(process_nutrients).apply(pd.Series)\n",
    "\n",
    "# Drop the original column \n",
    "main.drop(columns=['nutrition'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view to check\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning tags and adding column for the number of tags per recipe\n",
    "main['tags'] = main['tags'].str.strip('[]').str.replace(\"'\", '').str.split(', ')\n",
    "main['n_tags'] = main['tags'].apply(lambda x: len(x))\n",
    "\n",
    "# view to check\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning ingredients by turning the values in that column into a proper list\n",
    "main['ingredients'] = main['ingredients'].str.strip('[]').str.replace(\"'\", '').str.split(', ')\n",
    "\n",
    "# view to check\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unnamed column - provides nothing\n",
    "main = main.drop('Unnamed: 0', axis=1)\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NA's\n",
    "n_missing = main.isna().sum()\n",
    "n_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate, Bivariate, and Aggregate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate some information\n",
    "time_n_rating = main[['id', 'minutes', 'n_steps', 'rating', 'avg_rating']].drop_duplicates()\n",
    "time_n_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first glance at minutes distribution\n",
    "fig = px.histogram(time_n_rating[['minutes']], x='minutes', nbins=15)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution reveals that minutes has a crazy outlier! We looked at it closer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate with da minutes\n",
    "cook_time = time_n_rating[['minutes']]\n",
    "cook_time.sort_values('minutes', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and saw that there was recipies that had cook times of hundreds of thousands of minutes, even a million! Thus we decided to reduce our dataframe using the IQR (Interquartile Range), where we would only look at the data where the cooktime in `minutes` fell above $Q1 - 1.5 \\times IQR$ and below $Q3 + 1.5 \\times IQR$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate\n",
    "# histogram post getting rid of the outlier cooktime\n",
    "Q1 = time_n_rating['minutes'].quantile(0.25)\n",
    "Q3 = time_n_rating['minutes'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers_condition = (time_n_rating['minutes'] > (Q3 + 1.5 * IQR)) | (time_n_rating['minutes'] < (Q1 - 1.5 * IQR))\n",
    "\n",
    "# Filter out the outliers\n",
    "clean_time = time_n_rating[~outliers_condition]\n",
    "\n",
    "px.histogram(clean_time, x = 'minutes', nbins=20, histnorm='density', title='Density Histogram of cook time for a recipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with no outliers\n",
    "fig = px.scatter(clean_time, x='minutes', y=clean_time.index, title=\"Minutes for a recipe without Outliers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of average rating\n",
    "px.histogram(time_n_rating[['avg_rating']], title='Average rating of different recipes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot of average rating across recipes\n",
    "px.box(time_n_rating['avg_rating'], x='avg_rating', title = 'average rating of recipes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate\n",
    "# without removing the outlier minutes scatterplot\n",
    "px.scatter(time_n_rating, x='avg_rating', y='minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the outlier minutes scatterplot with a line of best fit\n",
    "\n",
    "fig = px.scatter(clean_time, x='avg_rating', y='minutes', trendline='ols', title='Cook time vs Average Rating of recipes')\n",
    "fig.update_traces(line_color='red')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting aggregates\n",
    "main.pivot_table(index='avg_rating',\n",
    "               columns='n_steps',\n",
    "               values='minutes',\n",
    "               aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to read part of this graph is, say, let's look at the first cell where the average rating is 1 and the recipe takes 1 step. A recipe that has an average rating of 1 and takes 1 step has an average cooking time of 12 minutes flat. All other cells can be read in a similar manner.\n",
    "\n",
    "From this table, we can also see that the most amount of steps in the entire main dataframe is a 100-step recipe. At 100 steps and an average rating of 5, the average cook time was 1680 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assessment of Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMAR Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews column is a column that could be deemed as NMAR, or not missing at random. After all, this is a dataset of food recipes and their respective reviews; a missing review for a recipe can really only be traced back to how a reviewer interacted with the recipe. The food could've have been so bad that the person felt no need to even leave a review, the recipe may or may not have ever been tried before for a review to be made, or human nature got in the way and the reviewer essentially just forgot to leave a review when logging their personal interaction. \n",
    "\n",
    "If we were to change the missingness from NMAR to MAR, where some other column in the dataset could explain the missingness of the `review` column, the additional data that we could possibly obtain would be information about user behavior or recipe characteristics. For example, there could be a column containing data on the difficulty level of the recipe. If a recipe is hard, maybe the person never even finished their attempt to finish the review. Another column of additional data we could possibly obtain is a column that evaluates the ingredients needed in the recipe. Some ingredients could be hard to find and some could be very expensive, which can affect whether or not a review is left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe the amt of views a recipe gets, completion, etc idk i was onto somethnig or maybe on somethng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at cols with missing values again\n",
    "n_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missingness Analysis/Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`better words blah blah `\n",
    "Missingess: avg ratings on diff-of-means for protein pdv (percent daily value)\n",
    "\n",
    "Non-missingness: avg ratings on diff-of-means for calories\n",
    "\n",
    "Significance Level: 0.05\n",
    "\n",
    "We chose to perform these tests on the data without the cook time (`minutes`) outlier because .... Additionally, because we are looking at average rating and columns that are inherent to the recipes and not interactions, we only kept the first occurance of every recipe in the DataFrame, removing rows corresponding to additional reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR elimination to deal with extreme outliers\n",
    "Q1 = main['minutes'].quantile(0.25)\n",
    "Q3 = main['minutes'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "iqr_conditions = ((main['minutes'] > (Q3 + IQR * 1.5)) | (main['minutes'] < (Q1 - IQR * 1.5)))\n",
    "iqr_main = main[~iqr_conditions]\n",
    "iqr_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_main['id'].nunique() #75056\n",
    "\n",
    "iqr_main_nd = iqr_main.drop_duplicates(subset='id', keep='first')\n",
    "iqr_main_nd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Mechanism 1 - MAR between average rating and n_steps\n",
    "m_rating_n_tag = iqr_main_nd[iqr_main_nd['avg_rating'].isna()]['protein_pdv'].mean()\n",
    "nm_rating_n_tag = iqr_main_nd[iqr_main_nd['avg_rating'].notna()]['protein_pdv'].mean()\n",
    "m_t_stat1 = m_rating_n_tag - nm_rating_n_tag\n",
    "m_t_stat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle avg rating column\n",
    "n = 500\n",
    "shuffler1 = iqr_main_nd.copy()\n",
    "\n",
    "diff_means1 = []\n",
    "for _ in range(n):\n",
    "    # shuffle the column \n",
    "    shuffler1['avg_rating'] = np.random.permutation(shuffler1['avg_rating'])\n",
    "    # determine the differences\n",
    "    dummy_na = shuffler1[shuffler1['avg_rating'].isna()]['protein_pdv'].mean()\n",
    "    dummy_isna = shuffler1[shuffler1['avg_rating'].notna()]['protein_pdv'].mean()\n",
    "    diff_means1.append(np.abs(dummy_na - dummy_isna))\n",
    "\n",
    "np.mean(np.array(diff_means1) >= np.abs(m_t_stat1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is 0.528, which is greater than our chosen significance level of 0.05. We can also see the distribution of our test statistics in comparison to our observed statistic below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'diff_means': diff_means1})\n",
    "\n",
    "# Create a histogram\n",
    "fig = px.histogram(df, x='diff_means', nbins=30, title='Permutation Test for MAR: average rating and protein')\n",
    "\n",
    "# Add a vertical line for the observed test statistic\n",
    "fig.add_vline(x=m_t_stat1, line=dict(color=\"red\", width=2, dash=\"dash\"), annotation_text=f'Observed Stat = {m_t_stat1:.3f}', annotation_position=\"top\")\n",
    "\n",
    "fig.update_layout(xaxis_title='Difference in Means', \n",
    "                  yaxis_title='Frequency',\n",
    "                  showlegend=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Mechanisms 2 - MAR is nonexistent between average rating and calories\n",
    "m_rating_cal = iqr_main_nd[iqr_main_nd['avg_rating'].isna()]['calories'].mean()\n",
    "nm_rating_cal = iqr_main_nd[iqr_main_nd['avg_rating'].notna()]['calories'].mean()\n",
    "m_t_stat2 = m_rating_cal - nm_rating_cal\n",
    "m_t_stat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle avg rating column\n",
    "n = 500\n",
    "shuffler2 = iqr_main_nd.copy()\n",
    "\n",
    "diff_means2 = []\n",
    "for _ in range(n):\n",
    "    # shuffle the column\n",
    "    shuffler2['avg_rating'] = np.random.permutation(shuffler2['avg_rating'])\n",
    "    # determine the differences\n",
    "    dummy_na = shuffler2[shuffler2['avg_rating'].isna()]['calories'].mean()\n",
    "    dummy_isna = shuffler2[shuffler2['avg_rating'].notna()]['calories'].mean()\n",
    "    diff_means2.append(np.abs(dummy_na - dummy_isna))\n",
    "\n",
    "np.mean(np.array(diff_means2) >= np.abs(m_t_stat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'diff_means': diff_means2})\n",
    "\n",
    "# Create a histogram\n",
    "fig = px.histogram(df2, x='diff_means', nbins=30, title='Permutation Test for MAR: average rating and calories')\n",
    "\n",
    "# Add a vertical line for the observed test statistic\n",
    "fig.add_vline(x=m_t_stat2, line=dict(color=\"red\", width=2, dash=\"dash\"), annotation_text=f'Observed Stat = {m_t_stat2:.3f}', annotation_position=\"top\")\n",
    "\n",
    "fig.update_layout(xaxis_title='Difference in Means', \n",
    "                  yaxis_title='Frequency',\n",
    "                  showlegend=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null: There is no relationship between average rating of a recipe and its cooking time.\n",
    "\n",
    "Alt: There is a relationship between the average rating of a recipe and its cooking time \n",
    "\n",
    "Using Pearson's R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "# observed test statistic, correlation between minutes and average rating\n",
    "obs_test_stat = iqr_main_nd['minutes'].corr(iqr_main_nd['avg_rating'])\n",
    "obs_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "shuffler3 = iqr_main_nd.copy()\n",
    "\n",
    "corrs = []\n",
    "for _ in range(n):\n",
    "    # shuffle the column \n",
    "    shuffler3['avg_rating'] = np.random.permutation(shuffler3['avg_rating'])\n",
    "    # determine the differences\n",
    "    dummy_corr = iqr_main['minutes'].corr(shuffler3['avg_rating'])\n",
    "    corrs.append(dummy_corr)\n",
    "\n",
    "np.mean(np.abs(corrs) >= np.abs(obs_test_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram \n",
    "fig = px.histogram(\n",
    "    x=corrs, \n",
    "    nbins=30, \n",
    "    opacity=0.7, \n",
    "    title=\"Permutation Test: Distribution of Shuffled Correlations\",\n",
    "    labels={\"x\": \"Shuffled Correlations\", \"y\": \"Frequency\"},\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Add observed test statistic as a vertical line\n",
    "fig.add_vline(x=obs_test_stat, line=dict(color=\"red\", width=2, dash=\"dash\"), annotation_text=\"Observed Test Stat\", annotation_position=\"top\")\n",
    "fig.add_vline(x=-np.abs(obs_test_stat), line=dict(color=\"blue\", width=2, dash=\"dash\"), annotation_text=\"- |Observed|\", annotation_position=\"top left\")\n",
    "fig.add_vline(x=np.abs(obs_test_stat), line=dict(color=\"blue\", width=2, dash=\"dash\"), annotation_text=\"+ |Observed|\", annotation_position=\"top right\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shown with a scatterplot as well\n",
    "fig = px.scatter(iqr_main, x=\"minutes\", y=\"avg_rating\", \n",
    "                 title=\"Scatter Plot of Minutes vs. Avg Rating\",\n",
    "                 labels={\"minutes\": \"Minutes\", \"avg_rating\": \"Average Rating\"},\n",
    "                 template=\"plotly_white\",\n",
    "                 trendline=\"ols\")  # Ordinary Least Squares Regression\n",
    "\n",
    "# Compute Pearson correlation coefficient (r)\n",
    "pearson_r = iqr_main['minutes'].corr(iqr_main['avg_rating'])\n",
    "\n",
    "# Add annotation with Pearson's r value\n",
    "fig.add_annotation(\n",
    "    x=min(iqr_main[\"minutes\"]),  # Position on the x-axis\n",
    "    y=max(iqr_main[\"avg_rating\"]),  # Position on the y-axis\n",
    "    text=f\"Pearson's r = {pearson_r:.3f}\",  # Show r rounded to 3 decimals\n",
    "    showarrow=False,\n",
    "    font=dict(size=14, color=\"black\"),\n",
    "    align=\"left\",\n",
    "    xanchor=\"left\",\n",
    "    yanchor=\"top\"\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "source": [
    "We are planning to predict the number of steps of a recipe based on cooking time and number of ingredients. This type of prediction problem is a regression type problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predictive Models\n",
    "# Training predictive model to predict number of steps based on cooking time and number of ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch Version\n",
    "# Data Split for Baseline Model\n",
    "X_b = iqr_main_nd[['minutes', 'n_ingredients']]\n",
    "Y_b = iqr_main_nd['n_steps']\n",
    "\n",
    "X_b_train, X_b_test, Y_b_train, Y_b_test = train_test_split(X_b, Y_b, test_size=0.2, random_state=42)\n",
    "\n",
    "# Column Transformer to apply PolynomialFeatures on 'minutes' and 'n_ingredients'\n",
    "col_trans_b = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), ['minutes', 'n_ingredients']),  # Apply poly to these columns\n",
    "        ('passthrough', 'passthrough', ['minutes', 'n_ingredients'])  # Keep other columns unchanged\n",
    "    ],\n",
    "    remainder='passthrough'  # All other columns pass through unchanged\n",
    ")\n",
    "\n",
    "# Pipeline with Polynomial Features and Linear Regression\n",
    "pipeline_b = Pipeline([\n",
    "    ('poly_transform', col_trans_b),      # Apply PolynomialFeature transformations\n",
    "    ('model', LinearRegression())         # Model to train\n",
    "])\n",
    "\n",
    "# Hyperparameter Grid for Polynomial Degree Tuning\n",
    "param_grid_b = {\n",
    "    'poly_transform__poly__degree': [1, 2, 3],  # Test polynomial degrees 1, 2, and 3\n",
    "    'model__fit_intercept': [True, False],       # Test if intercept improves performance\n",
    "    'model__positive': [True, False]             # Test if coefficients should remain non-negative\n",
    "}\n",
    "\n",
    "# GridSearchCV for Hyperparameter Tuning\n",
    "grid_search_b = GridSearchCV(pipeline_b, param_grid_b, cv=10, scoring='r2')\n",
    "grid_search_b.fit(X_b_train, Y_b_train)\n",
    "\n",
    "# Evaluation\n",
    "best_model_b = grid_search_b.best_estimator_\n",
    "y_b_pred = best_model_b.predict(X_b_test)\n",
    "\n",
    "print(f'Best R² Score for Baseline Model: {r2_score(Y_b_test, y_b_pred):.4f}')\n",
    "print(f'Best Parameters for Baseline Model: {grid_search_b.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from the best model\n",
    "y_b_pred = best_model_b.predict(X_b_test)\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Steps': Y_b_test,  # Use the test set labels (Actual Steps)\n",
    "    'Predicted Steps': y_b_pred  # Use the predicted values\n",
    "})\n",
    "\n",
    "# Scatter plot using Plotly\n",
    "fig = px.scatter(\n",
    "    results_df, \n",
    "    x='Actual Steps', \n",
    "    y='Predicted Steps',\n",
    "    title='Actual vs. Predicted Number of Steps',\n",
    "    opacity=0.5,  # Equivalent to `alpha` in matplotlib\n",
    ")\n",
    "\n",
    "# Final touches to layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Actual Steps',\n",
    "    yaxis_title='Predicted Steps',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from the best model\n",
    "y_b_pred = best_model_b.predict(X_b_test)\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted Steps': y_b_pred  # Use predictions from the best model\n",
    "})\n",
    "\n",
    "# Distribution plot\n",
    "fig = px.histogram(\n",
    "    results_df, \n",
    "    x='Predicted Steps',\n",
    "    nbins=30,  # Adjust the number of bins as needed\n",
    "    title='Distribution of Predicted Steps',\n",
    "    marginal='box',  # Adds a box plot for additional insights\n",
    ")\n",
    "\n",
    "# Final touches to layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Predicted Steps',\n",
    "    yaxis_title='Count',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot 1: Number of Steps vs Cooking Minutes\n",
    "fig1 = px.scatter(\n",
    "    iqr_main_nd, \n",
    "    x='minutes', \n",
    "    y='n_steps',\n",
    "    title='Number of Steps vs Cooking Minutes',\n",
    "    labels={'minutes': 'Cooking Minutes', 'n_steps': 'Number of Steps'},\n",
    "    opacity=0.5\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# Scatter plot 2: Number of Steps vs Number of Ingredients\n",
    "fig2 = px.scatter(\n",
    "    iqr_main_nd, \n",
    "    x='n_ingredients', \n",
    "    y='n_steps',\n",
    "    title='Number of Steps vs Number of Ingredients',\n",
    "    labels={'n_ingredients': 'Number of Ingredients', 'n_steps': 'Number of Steps'},\n",
    "    opacity=0.5\n",
    ")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearch Version\n",
    "# Data Split for Baseline Model\n",
    "X_b = iqr_main_nd[['minutes', 'n_ingredients']]\n",
    "Y_b = iqr_main_nd['n_steps']\n",
    "\n",
    "X_b_train, X_b_test, Y_b_train, Y_b_test = train_test_split(X_b, Y_b, test_size=0.2, random_state=42)\n",
    "\n",
    "# Column Transformer to apply PolynomialFeatures on 'minutes' and 'n_ingredients'\n",
    "col_trans_b = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), ['minutes', 'n_ingredients']),  # Apply poly to these columns\n",
    "        ('passthrough', 'passthrough', ['minutes', 'n_ingredients'])  # Keep other columns unchanged\n",
    "    ],\n",
    "    remainder='passthrough'  # All other columns pass through unchanged\n",
    ")\n",
    "\n",
    "# Pipeline with Polynomial Features and Linear Regression\n",
    "pipeline_b = Pipeline([\n",
    "    ('poly_transform', col_trans_b),      # Apply PolynomialFeature transformations\n",
    "    ('model', LinearRegression())         # Model to train\n",
    "])\n",
    "\n",
    "# Hyperparameter Distribution for Polynomial Degree Tuning\n",
    "param_dist_b = {\n",
    "    'poly_transform__poly__degree': [1, 2, 3],  # Test polynomial degrees 1, 2, and 3\n",
    "    'model__fit_intercept': [True, False],       # Test if intercept improves performance\n",
    "    'model__positive': [True, False]             # Test if coefficients should remain non-negative\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for Hyperparameter Tuning\n",
    "random_search_b = RandomizedSearchCV(pipeline_b, param_dist_b, n_iter=10, cv=10, scoring='r2', random_state=42)\n",
    "random_search_b.fit(X_b_train, Y_b_train)\n",
    "\n",
    "# Evaluation\n",
    "best_model_b = random_search_b.best_estimator_\n",
    "y_b_pred = best_model_b.predict(X_b_test)\n",
    "\n",
    "print(f'Best R² Score for Baseline Model: {r2_score(Y_b_test, y_b_pred):.4f}')\n",
    "print(f'Best Parameters for Baseline Model: {random_search_b.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column to indicate if an oven is required\n",
    "iqr_main_nd = iqr_main_nd.assign(oven_req=iqr_main['steps'].str.contains('oven'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for transforming oven requirement column\n",
    "def bool_converter(s):\n",
    "    return s.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV version\n",
    "# Column transformer to handle specific feature transformations\n",
    "col_trans_f = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), ['minutes', 'n_ingredients']),  # Apply polynomial features on these columns\n",
    "        ('log', FunctionTransformer(np.log1p), ['calories']),  # Log transform the 'calories' column\n",
    "        ('bool', FunctionTransformer(bool_converter), ['oven_req'])  # Convert 'oven_req' column to int\n",
    "    ],\n",
    "    remainder='passthrough'  # All other columns pass through unchanged\n",
    ")\n",
    "\n",
    "# Variables (features and target)\n",
    "X_f = iqr_main_nd[['minutes', 'n_ingredients', 'calories', 'oven_req']]  # Features\n",
    "Y_f = iqr_main_nd['n_steps']  # Target\n",
    "\n",
    "# Train-test split (80% training, 20% testing)\n",
    "X_f_train, X_f_test, Y_f_train, Y_f_test = train_test_split(X_f, Y_f, test_size=0.2, random_state=42)\n",
    "\n",
    "# Make a new pipeline\n",
    "pipeline_f = Pipeline([\n",
    "    ('col_transform', col_trans_f),  # Apply column transformations (poly features, log, passthrough)\n",
    "    ('model', LinearRegression())  # Use LinearRegression as the model\n",
    "])\n",
    "\n",
    "# Hyperparameter grid for polynomial degree tuning and model settings\n",
    "param_grid_f = {\n",
    "    'col_transform__poly__degree': [1, 2, 3],  # Test polynomial degrees 1, 2, and 3 for 'minutes' and 'n_ingredients'\n",
    "    'model__fit_intercept': [True, False],  # Test whether the intercept improves performance\n",
    "    'model__positive': [True, False]  # Test whether to constrain coefficients to remain non-negative\n",
    "}\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search_f = GridSearchCV(pipeline_f, param_grid_f, cv=10, scoring='r2')\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_f.fit(X_f_train, Y_f_train)\n",
    "\n",
    "# Evaluation\n",
    "best_model_f = grid_search_f.best_estimator_\n",
    "y_f_pred = best_model_f.predict(X_f_test)\n",
    "\n",
    "# Print results\n",
    "print(f'Best R² Score for Final Model: {grid_search_f.best_score_:.4f}')\n",
    "print(f'Best Parameters for Final Model: {grid_search_f.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV version\n",
    "\n",
    "# Column transformer to handle specific feature transformations\n",
    "col_trans_f = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('poly', PolynomialFeatures(), ['minutes', 'n_ingredients']),  # Apply polynomial features on these columns\n",
    "        ('log', FunctionTransformer(np.log1p), ['calories']),  # Log transform the 'calories' column\n",
    "        ('bool', FunctionTransformer(bool_converter), ['oven_req'])  # Convert 'oven_req' column to int\n",
    "    ],\n",
    "    remainder='passthrough'  # All other columns pass through unchanged\n",
    ")\n",
    "\n",
    "# Variables (features and target)\n",
    "X_f = iqr_main_nd[['minutes', 'n_ingredients', 'calories', 'oven_req']]  # Features\n",
    "Y_f = iqr_main_nd['n_steps']  # Target\n",
    "\n",
    "# Train-test split (80% training, 20% testing)\n",
    "X_f_train, X_f_test, Y_f_train, Y_f_test = train_test_split(X_f, Y_f, test_size=0.2, random_state=42)\n",
    "\n",
    "# Make a new pipeline\n",
    "pipeline_f = Pipeline([\n",
    "    ('col_transform', col_trans_f),  # Apply column transformations (poly features, log, passthrough)\n",
    "    ('model', LinearRegression())  # Use LinearRegression as the model\n",
    "])\n",
    "\n",
    "# Hyperparameter distribution for polynomial degree tuning and model settings\n",
    "param_dist_f = {\n",
    "    'col_transform__poly__degree': [1, 2, 3],  # Test polynomial degrees 1, 2, and 3 for 'minutes' and 'n_ingredients'\n",
    "    'model__fit_intercept': [True, False],  # Test whether the intercept improves performance\n",
    "    'model__positive': [True, False]  # Test whether to constrain coefficients to remain non-negative\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "random_search_f = RandomizedSearchCV(pipeline_f, param_dist_f, n_iter=10, cv=10, scoring='r2', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search_f.fit(X_f_train, Y_f_train)\n",
    "\n",
    "# Evaluation\n",
    "best_model_f = random_search_f.best_estimator_\n",
    "y_f_pred = best_model_f.predict(X_f_test)\n",
    "\n",
    "# Print results\n",
    "print(f'Best R² Score for Final Model: {random_search_f.best_score_:.4f}')\n",
    "print(f'Best Parameters for Final Model: {random_search_f.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
